# -*- coding: utf-8 -*-
"""predict_mental_health.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LRTVd6LgII9w7CBygIt4ghwj_vheAT1x
"""

!pip install lime

import numpy as np
import pandas as pd
import seaborn as sns
import lime
import lime.lime_tabular
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split,GridSearchCV
from sklearn.preprocessing import StandardScaler,LabelEncoder,OneHotEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, BaggingClassifier,RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score,confusion_matrix,classification_report,roc_auc_score,roc_curve, auc
pd.set_option('display.max_columns',None)

df = pd.read_csv('survey.csv')

df.head()

df.shape

df.info()

df.isnull().sum()

df.drop(columns=['Timestamp','comments'],inplace=True)

df['state'] = df['state'].fillna(df['state'].mode()[0])
df['work_interfere'] = df['work_interfere'].fillna(df['work_interfere'].mode()[0])

for col in df.columns:
    print(f"Unique values in column '{col}': {df[col].unique()}")
    print("-" * 40)

def clean_gender(gender):
    if isinstance(gender, str):
        gender = gender.lower()
        if 'm' in gender:
            return 'male'
        elif 'f' in gender:
            return 'female'
        else:
            return 'other'
    else:
        return 'other'

df['Gender'] = df['Gender'].apply(clean_gender)

df['Gender'].unique()

df = df[df['self_employed'].notna()]
print(df['self_employed'].unique())

def categorize_employees(x):
    if x == '1-5':
        return 1
    elif x == '6-25':
        return 2
    elif x == '26-100':
        return 3
    elif x == '100-500':
        return 4
    elif x == '500-1000':
        return 5
    elif x == 'More than 1000':
        return 6
    else:
        return 0 # Handle any other values as needed

# Apply the function to the 'no_employees' column
df['no_employees'] = df['no_employees'].apply(categorize_employees)

df = df[(df['Age'] <= 80) & (df['Age'] > 0) & (df['Age'] >= 20)]

df.head()

for col in df.columns:
    print(f"Unique values in column '{col}': {df[col].unique()}")
    print("-" * 40)

le = LabelEncoder()

for col in df.columns:
    if col not in ['Age', 'no_employees']:
        df[col] = le.fit_transform(df[col])

df.head()

for col in df.columns:
    print(f"Encoded values for '{col}':")
    print(df[col].unique())
    print("-" * 40)

plt.figure(figsize=(12, 6))
plt.subplot(2, 3, 1)
sns.countplot(x='Gender', data=df)
plt.title('Gender Distribution')

plt.subplot(2, 3, 2)
sns.histplot(df['Age'], kde=True)
plt.title('Age Distribution')

plt.subplot(2, 3, 3)
sns.countplot(x='no_employees', data=df)
plt.title('Number of Employees Distribution')

plt.subplot(2, 3, 4)
sns.countplot(x='self_employed', data=df)
plt.title('Self Employed Distribution')

plt.subplot(2, 3, 5)
sns.countplot(x='family_history', data=df)
plt.title('Family History of Mental Health Issues')

plt.subplot(2, 3, 6)
sns.countplot(x='treatment', data=df)
plt.title('Treatment for Mental Health')

plt.tight_layout()
plt.show()

plt.figure(figsize=(8, 6))
sns.boxplot(x='treatment', y='Age', data=df)
plt.title('Age Distribution by Treatment')
plt.show()

def remove_outliers(group):
    Q1 = group.quantile(0.25)
    Q3 = group.quantile(0.75)
    IQR = Q3 - Q1
    return group[~((group < (Q1 - 1.5 * IQR)) | (group > (Q3 + 1.5 * IQR)))]

# Apply the function for each treatment group
filtered_df = df.groupby('treatment')['Age'].apply(remove_outliers).reset_index()

print(filtered_df)

sns.boxplot(x='treatment', y='Age', data=filtered_df)
plt.show()

sns.pairplot(df[['Age', 'no_employees', 'treatment', 'Gender']], hue='treatment')
plt.show()

plt.figure(figsize=(8, 6))
sns.violinplot(x='treatment', y='Age', data=df)
plt.title('Age Distribution by Treatment (Violin Plot)')
plt.show()

plt.figure(figsize=(18, 10))
correlation_matrix = df.corr()
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f")
plt.title('Correlation Matrix')
plt.show()

X = df.drop(columns=['treatment'],axis=1)
Y = df['treatment']

X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2,random_state=42)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

"""# **LOGISTIC REGRESSION**"""

lr = LogisticRegression()
lr.fit(X_train_scaled,Y_train)

Y_pred = lr.predict(X_test_scaled)
Y_pred

accuracy_score(Y_test,Y_pred)

print(classification_report(Y_test,Y_pred))

print(confusion_matrix(Y_test,Y_pred))

sns.heatmap(confusion_matrix(Y_test,Y_pred),annot=True,fmt='d')
plt.show()

"""# **RANDOM FOREST CLASSIFER USING GRIDSEARCH CV**"""

param_grid_rfc = {
    'n_estimators': [50, 100, 200],
    'max_depth': [None, 10, 20],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}

grid_search_rfc = GridSearchCV(estimator=RandomForestClassifier(random_state=42), param_grid=param_grid_rfc, cv=5, scoring='accuracy')
grid_search_rfc.fit(X_train_scaled, Y_train)

best_rfc = grid_search_rfc.best_estimator_
y_pred_rfc = best_rfc.predict(X_test_scaled)
accuracy_rfc = accuracy_score(Y_test, y_pred_rfc)
print(f"Best Random Forest Accuracy: {accuracy_rfc}")

print(classification_report(Y_test,y_pred_rfc))

sns.heatmap(confusion_matrix(Y_test,y_pred_rfc),annot=True,fmt='d')
plt.show()

explainer = lime.lime_tabular.LimeTabularExplainer(X_train_scaled,
                                                   feature_names=X_train.columns,
                                                   class_names=['treatment_0', 'treatment_1'], # Replace with your class names
                                                   discretize_continuous=True)

# Choose an instance to explain (e.g., the first instance in X_test_scaled)
idx = 0
instance = X_test_scaled[idx]

# Generate the explanation
explanation = explainer.explain_instance(instance, best_rfc.predict_proba, num_features=10)

# Now you can plot the explanation
fig = explanation.as_pyplot_figure()
plt.title(f'LIME Explanation for Instance {idx}', fontsize=14)
plt.xlabel('Feature Contribution', fontsize=12)
plt.grid(True, linestyle='--', alpha=0.6)

# Customize bar colors and text
bars = plt.gca().patches
for bar in bars:
    if bar.get_width() > 0:
        bar.set_color('green')
    else:
        bar.set_color('red')

plt.tight_layout()
plt.show()

y_pred_rfc_prob = best_rfc.predict_proba(X_test_scaled)[:,1] # Probabilities for class 1
roc_auc = roc_auc_score(Y_test, y_pred_rfc_prob)
print(f"ROC-AUC Score: {roc_auc}")

fpr, tpr, thresholds = roc_curve(Y_test, y_pred_rfc_prob)
roc_auc = auc(fpr, tpr)

plt.figure()
plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC)')
plt.legend(loc="lower right")
plt.show()

"""# **DECISION TREE CLASSIFIER USING GRIDSEARCH CV**"""

param_grid_dt = {
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4],
    'criterion': ['gini', 'entropy']
}

grid_search_dt = GridSearchCV(estimator=DecisionTreeClassifier(random_state=42), param_grid=param_grid_dt, cv=5, scoring='accuracy')
grid_search_dt.fit(X_train_scaled, Y_train)

best_dt = grid_search_dt.best_estimator_
y_pred_dt = best_dt.predict(X_test_scaled)
accuracy_dt = accuracy_score(Y_test, y_pred_dt)
print(f"Best Decision Tree Accuracy: {accuracy_dt}")

print(classification_report(Y_test,y_pred_dt))

sns.heatmap(confusion_matrix(Y_test,y_pred_dt),annot=True,fmt='d')
plt.show()

"""# **GRADIENT BOOSTING CLASSIFIER**"""

gbc = GradientBoostingClassifier(n_estimators=100, random_state=42) # Adjust n_estimators as needed
gbc.fit(X_train_scaled, Y_train)

y_pred_gbc = gbc.predict(X_test_scaled)
accuracy_gbc = accuracy_score(Y_test, y_pred_gbc)
print(f"Best Gradient Boosting Accuracy: {accuracy_gbc}")

print(classification_report(Y_test, y_pred_gbc))

sns.heatmap(confusion_matrix(Y_test, y_pred_gbc), annot=True, fmt='d')

model_accuracies = {
    'Logistic Regression': 0.73,
    'Random Forest': 0.78,
    'Decision Tree': 0.74,
    'Gradient Boosting' : 0.75
}

models = list(model_accuracies.keys())
accuracies = list(model_accuracies.values())

plt.figure(figsize=(10, 6))
plt.bar(models, accuracies, color=['red', 'green', 'blue','purple','orange'])
plt.xlabel("Models")
plt.ylabel("Accuracy")
plt.title("Accuracy of Different Models")
plt.ylim(0, 1)
plt.show()

"""# **As we can see clearly the accuracy of Random forest classifier is higher than every other model so i am selecting Random Forest Classifier**"""

importances = best_rfc.feature_importances_
feature_names = X.columns

feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})
feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)

top_features = feature_importance_df.head(10)

plt.figure(figsize=(10, 6))
plt.barh(top_features['Feature'], top_features['Importance'])
plt.xlabel("Importance")
plt.ylabel("Feature")
plt.title("Top 10 Important Features")
plt.gca().invert_yaxis()
plt.show()

import pickle
with open('rfc_model.pkl', 'wb') as file:
    pickle.dump(best_rfc, file)

